{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "# from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from modules import components, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELANE_NAME = \"stroke-detect-pipeline\"\n",
    "\n",
    "# Pipeline inputs\n",
    "DATA_ROOT = \"data\"\n",
    "TRANSFORM_MODULE_FILE = \"modules/transform.py\"\n",
    "TUNER_MODULE_FILE = \"modules/tuner.py\"\n",
    "TRAINER_MODULE_FILE = \"modules/trainer.py\"\n",
    "\n",
    "# Pipeline outputs\n",
    "OUTPUT_BASE = \"outputs\"\n",
    "\n",
    "serving_model_dir = os.path.join(OUTPUT_BASE, \"serving_model\")\n",
    "pipeline_root = os.path.join(OUTPUT_BASE, PIPELANE_NAME)\n",
    "metadata_path = os.path.join(pipeline_root, \"metadata.sqlite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying components.py -> build/lib\n",
      "copying trainer.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transform.py -> build/lib\n",
      "installing to /tmp/tmp_8s9g6ll\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/components.py -> /tmp/tmp_8s9g6ll\n",
      "copying build/lib/trainer.py -> /tmp/tmp_8s9g6ll\n",
      "copying build/lib/pipeline.py -> /tmp/tmp_8s9g6ll\n",
      "copying build/lib/tuner.py -> /tmp/tmp_8s9g6ll\n",
      "copying build/lib/transform.py -> /tmp/tmp_8s9g6ll\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmp_8s9g6ll/tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmp_8s9g6ll/tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/WHEEL\n",
      "creating '/tmp/tmpg_sa6jn6/tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3-none-any.whl' and adding '/tmp/tmp_8s9g6ll' to it\n",
      "adding 'components.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'trainer.py'\n",
      "adding 'transform.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/RECORD'\n",
      "removing /tmp/tmp_8s9g6ll\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gadzz/.conda/envs/mlops-tfx/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying components.py -> build/lib\n",
      "copying trainer.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transform.py -> build/lib\n",
      "installing to /tmp/tmp6eo34e6s\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/components.py -> /tmp/tmp6eo34e6s\n",
      "copying build/lib/trainer.py -> /tmp/tmp6eo34e6s\n",
      "copying build/lib/pipeline.py -> /tmp/tmp6eo34e6s\n",
      "copying build/lib/tuner.py -> /tmp/tmp6eo34e6s\n",
      "copying build/lib/transform.py -> /tmp/tmp6eo34e6s\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Tuner.egg-info\n",
      "writing tfx_user_code_Tuner.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Tuner.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Tuner.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Tuner.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Tuner.egg-info to /tmp/tmp6eo34e6s/tfx_user_code_Tuner-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmp6eo34e6s/tfx_user_code_Tuner-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/WHEEL\n",
      "creating '/tmp/tmpvdas1n6p/tfx_user_code_Tuner-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3-none-any.whl' and adding '/tmp/tmp6eo34e6s' to it\n",
      "adding 'components.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'trainer.py'\n",
      "adding 'transform.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Tuner-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Tuner-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Tuner-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Tuner-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/RECORD'\n",
      "removing /tmp/tmp6eo34e6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gadzz/.conda/envs/mlops-tfx/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying components.py -> build/lib\n",
      "copying trainer.py -> build/lib\n",
      "copying pipeline.py -> build/lib\n",
      "copying tuner.py -> build/lib\n",
      "copying transform.py -> build/lib\n",
      "installing to /tmp/tmpvd6cqdux\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/components.py -> /tmp/tmpvd6cqdux\n",
      "copying build/lib/trainer.py -> /tmp/tmpvd6cqdux\n",
      "copying build/lib/pipeline.py -> /tmp/tmpvd6cqdux\n",
      "copying build/lib/tuner.py -> /tmp/tmpvd6cqdux\n",
      "copying build/lib/transform.py -> /tmp/tmpvd6cqdux\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmpvd6cqdux/tfx_user_code_Trainer-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3.9.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmpvd6cqdux/tfx_user_code_Trainer-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/WHEEL\n",
      "creating '/tmp/tmptywttm7e/tfx_user_code_Trainer-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3-none-any.whl' and adding '/tmp/tmpvd6cqdux' to it\n",
      "adding 'components.py'\n",
      "adding 'pipeline.py'\n",
      "adding 'trainer.py'\n",
      "adding 'transform.py'\n",
      "adding 'tuner.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00.dist-info/RECORD'\n",
      "removing /tmp/tmpvd6cqdux\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gadzz/.conda/envs/mlops-tfx/lib/python3.9/site-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n",
      "WARNING:absl:ArtifactQuery.property_predicate is not supported.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./outputs/stroke-detect-pipeline/_wheels/tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00\n",
      "Processing ./outputs/stroke-detect-pipeline/_wheels/tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00\n",
      "Processing ./outputs/stroke-detect-pipeline/_wheels/tfx_user_code_Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+580ff50989875c54b295ad845f977b2e5d622bc93d372ca7226e82d5abb2fd00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_1/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_2/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_3/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_4/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_5/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:absl:Tables initialized inside a tf.function  will be re-initialized on every invocation of the function. This  re-initialization can have significant impact on performance. Consider lifting  them out of the graph context using  `tf.init_scope`.: compute_and_apply_vocabulary_6/apply_vocab/text_file_init/InitializeTableFromTextFileV2\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: Tuple[Dict[<class 'str'>, Union[<class 'NoneType'>, <class 'tfx.components.transform.executor._Dataset'>]], Union[<class 'NoneType'>, Dict[<class 'str'>, Dict[<class 'str'>, <class 'apache_beam.pvalue.PCollection'>]]], <class 'int'>] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deep copying inputs for phase: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deep copying inputs for phase: 1\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n",
      "WARNING:root:This input type hint will be ignored and not used for type-checking purposes. Typically, input type hints for a PTransform are single (or nested) types wrapped by a PCollection, or PBegin. Got: Dict[<class 'tensorflow_transform.beam.analyzer_cache.DatasetKey'>, <class 'tensorflow_transform.beam.analyzer_cache.DatasetCache'>] instead.\n",
      "WARNING:root:This output type hint will be ignored and not used for type-checking purposes. Typically, output type hints for a PTransform are single (or nested) types wrapped by a PCollection, PDone, or None. Got: List[<class 'apache_beam.pvalue.PDone'>] instead.\n"
     ]
    }
   ],
   "source": [
    "components_args = {\n",
    "    \"data_dir\": DATA_ROOT,\n",
    "    \"trainer_module\": TRAINER_MODULE_FILE,\n",
    "    \"tuner_module\": TUNER_MODULE_FILE,\n",
    "    \"transform_module\": TRANSFORM_MODULE_FILE,\n",
    "    \"train_steps\": 1000,\n",
    "    \"eval_steps\": 800,\n",
    "    \"serving_model_dir\": serving_model_dir,\n",
    "}\n",
    "\n",
    "components = components.init_components(components_args)\n",
    "\n",
    "pipeline = pipeline.init_pipeline(\n",
    "    pipeline_root, \n",
    "    PIPELANE_NAME, \n",
    "    metadata_path, \n",
    "    components\n",
    ")\n",
    "BeamDagRunner().run(pipeline)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-tfx2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
